@article{gbu,
   title={Zero-Shot Learning — The Good, the Bad and the Ugly},
   ISBN={9781538604571},
   url={http://dx.doi.org/10.1109/CVPR.2017.328},
   DOI={10.1109/cvpr.2017.328},
   journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Xian, Yongqin and Schiele, Bernt and Akata, Zeynep},
   year={2017},
   month={07}
}

@INPROCEEDINGS{ale,
  author={Z. {Akata} and F. {Perronnin} and Z. {Harchaoui} and C. {Schmid}},
  booktitle={2013 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Label-Embedding for Attribute-Based Classification}, 
  year={2013},
  volume={},
  number={},
  pages={819-826},}

@article{awa,
  title={Attribute-Based Classification for Zero-Shot Visual Object Categorization},
  author={Christoph H. Lampert and H. Nickisch and S. Harmeling},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2014},
  volume={36},
  pages={453-465}
}


@INPROCEEDINGS{sun,
  author={G. {Patterson} and J. {Hays}},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={SUN attribute database: Discovering, annotating, and recognizing scene attributes}, 
  year={2012},
  volume={},
  number={},
  pages={2751-2758},}
  
@misc{cetin,
    author       = {cetinsamet},
    title        = {{attribute-label-embedding}},
    month        = dec,
    year         = 2019,
    url          = {https://github.com/cetinsamet/attribute-label-embedding.git}
    }

@article{zero-shot-survey,
author = {Wang, Wei and Zheng, Vincent W. and Yu, Han and Miao, Chunyan},
title = {A Survey of Zero-Shot Learning: Settings, Methods, and Applications},
year = {2019},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3293318},
doi = {10.1145/3293318},
abstract = {Most machine-learning methods focus on classifying instances whose classes have already been seen in training. In practice, many applications require classifying instances whose classes have not been seen previously. Zero-shot learning is a powerful and promising learning paradigm, in which the classes covered by training instances and the classes we aim to classify are disjoint. In this paper, we provide a comprehensive survey of zero-shot learning. First of all, we provide an overview of zero-shot learning. According to the data utilized in model optimization, we classify zero-shot learning into three learning settings. Second, we describe different semantic spaces adopted in existing zero-shot learning works. Third, we categorize existing zero-shot learning methods and introduce representative methods under each category. Fourth, we discuss different applications of zero-shot learning. Finally, we highlight promising future research directions of zero-shot learning.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jan,
articleno = {13},
numpages = {37},
keywords = {Zero-shot learning survey}
}

@ARTICLE{DAP,
  author={C. H. {Lampert} and H. {Nickisch} and S. {Harmeling}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Attribute-Based Classification for Zero-Shot Visual Object Categorization}, 
  year={2014},
  volume={36},
  number={3},
  pages={453-465},
  doi={10.1109/TPAMI.2013.140}}

@article{domainshift,
   title={Transductive Multi-View Zero-Shot Learning},
   volume={37},
   ISSN={2160-9292},
   url={http://dx.doi.org/10.1109/TPAMI.2015.2408354},
   DOI={10.1109/tpami.2015.2408354},
   number={11},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Fu, Yanwei and Hospedales, Timothy M. and Xiang, Tao and Gong, Shaogang},
   year={2015},
   month={11},
   pages={2332–2345}
}

@inproceedings{devise,
 author = {Frome, Andrea and Corrado, Greg S and Shlens, Jon and Bengio, Samy and Dean, Jeff and Ranzato, Marc\textquotesingle Aurelio and Mikolov, Tomas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
 pages = {2121--2129},
 publisher = {Curran Associates, Inc.},
 title = {DeViSE: A Deep Visual-Semantic Embedding Model},
 url = {https://proceedings.neurips.cc/paper/2013/file/7cce53cf90577442771720a370c3c723-Paper.pdf},
 volume = {26},
 year = {2013}
}

@article{SJE,
   title={Evaluation of output embeddings for fine-grained image classification},
   ISBN={9781467369640},
   url={http://dx.doi.org/10.1109/CVPR.2015.7298911},
   DOI={10.1109/cvpr.2015.7298911},
   journal={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Akata, Zeynep and Reed, Scott and Walter, Daniel and Honglak Lee and Schiele, Bernt},
   year={2015},
   month={06}
}

@inproceedings{ESZSL, 
author = {Romera-Paredes, Bernardino and Torr, Philip H. S.}, 
title = {An Embarrassingly Simple Approach to Zero-Shot Learning}, 
year = {2015}, 
publisher = {JMLR.org}, 
abstract = {Zero-shot learning consists in learning how to recognise new concepts by just having a description of them. Many sophisticated approaches have been proposed to address the challenges this problem comprises. In this paper we describe a zero-shot learning approach that can be implemented in just one line of code, yet it is able to outperform state of the art approaches on standard datasets. The approach is based on a more general framework which models the relationships between features, attributes, and classes as a two linear layers network, where the weights of the top layer are not learned but are given by the environment. We further provide a learning bound on the generalisation error of this kind of approaches, by casting them as domain adaptation methods. In experiments carried out on three standard real datasets, we found that our approach is able to perform significantly better than the state of art on all of them, obtaining a ratio of improvement up to 17.}, booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37}, pages = {2152–2161}, numpages = {10}, location = {Lille, France}, series = {ICML'15} }

@misc{LATEM,
      title={Latent Embeddings for Zero-shot Classification}, 
      author={Yongqin Xian and Zeynep Akata and Gaurav Sharma and Quynh Nguyen and Matthias Hein and Bernt Schiele},
      year={2016},
      eprint={1603.08895},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{CMT, author = {Socher, Richard and Ganjoo, Milind and Manning, Christopher D. and Ng, Andrew Y.}, title = {Zero-Shot Learning through Cross-Modal Transfer}, year = {2013}, publisher = {Curran Associates Inc.}, address = {Red Hook, NY, USA}, abstract = {This work introduces a model that can recognize objects in images even if no training data is available for the object class. The only necessary knowledge about unseen visual categories comes from unsupervised text corpora. Unlike previous zero-shot learning models, which can only differentiate between unseen classes, our model can operate on a mixture of seen and unseen classes, simultaneously obtaining state of the art performance on classes with thousands of training images and reasonable performance on unseen classes. This is achieved by seeing the distributions of words in texts as a semantic space for understanding what objects look like. Our deep learning model does not require any manually defined semantic or visual features for either words or images. Images are mapped to be close to semantic word vectors corresponding to their classes, and the resulting image embeddings can be used to distinguish whether an image is of a seen or unseen class. We then use novelty detection methods to differentiate unseen classes from seen classes. We demonstrate two novelty detection strategies; the first gives high accuracy on unseen classes, while the second is conservative in its prediction of novelty and keeps the seen classes' accuracy high.}, booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 1}, pages = {935–943}, numpages = {9}, location = {Lake Tahoe, Nevada}, series = {NIPS'13} }

@misc{w2v,
      title={Distributed Representations of Words and Phrases and their Compositionality}, 
      author={Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1310.4546},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{sse,
  author    = {Ziming Zhang and
               Venkatesh Saligrama},
  title     = {Zero-Shot Learning via Semantic Similarity Embedding},
  journal   = {CoRR},
  volume    = {abs/1509.04767},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.04767},
  archivePrefix = {arXiv},
  eprint    = {1509.04767},
  timestamp = {Mon, 13 Aug 2018 16:48:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZhangS15d.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@conference{conse,
title = "Zero-shot learning by convex combination of semantic embeddings",
abstract = "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise for zero-shot learning – the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing n-way image classifier and a semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.",
author = "Mohammad Norouzi and Tomas Mikolov and Samy Bengio and Yoram Singer and Jonathon Shlens and Andrea Frome and Corrado, {Greg S.} and Jeffrey Dean",
year = "2014",
month = jan,
day = "1",
language = "English (US)",
note = "2nd International Conference on Learning Representations, ICLR 2014 ; Conference date: 14-04-2014 Through 16-04-2014",
}

@misc{sync,
      title={Synthesized Classifiers for Zero-Shot Learning}, 
      author={Soravit Changpinyo and Wei-Lun Chao and Boqing Gong and Fei Sha},
      year={2016},
      eprint={1603.00550},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gfzsl,
      title={A Simple Exponential Family Framework for Zero-Shot Learning}, 
      author={Vinay Kumar Verma and Piyush Rai},
      year={2018},
      eprint={1707.08040},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{fgn,
      title={Feature Generating Networks for Zero-Shot Learning}, 
      author={Yongqin Xian and Tobias Lorenz and Bernt Schiele and Zeynep Akata},
      year={2018},
      eprint={1712.00981},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{gcn,
      title={Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs}, 
      author={Xiaolong Wang and Yufei Ye and Abhinav Gupta},
      year={2018},
      eprint={1803.08035},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@inproceedings {LISGAN, 	
 title = {Leveraging the Invariant Side of Generative Zero-Shot Learning}, 	
 booktitle = {IEEE Computer Vision and Pattern Recognition (CVPR)}, 	
 year = {2019}, 	
 author = {Li, Jingjing and Jing, Mengmeng and Lu, Ke and Ding, Zhengming and Zhu, Lei and Huang, Zi} 
} 

@misc{lsrGAN,
      title={Leveraging Seen and Unseen Semantic Relationships for Generative Zero-Shot Learning}, 
      author={Maunil R Vyas and Hemanth Venkateswara and Sethuraman Panchanathan},
      year={2020},
      eprint={2007.09549},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{tf-vegan,
  title={Latent Embedding Feedback and Discriminative Features for Zero-Shot Classification},
  author={Narayan, Sanath and Gupta, Akshita and Khan, Fahad Shahbaz and Snoek, Cees GM and Shao, Ling},
  journal={arXiv preprint arXiv:2003.07833},
  year={2020}
}

@techreport{cub,
	Author = {P. Welinder and S. Branson and T. Mita and C. Wah and F. Schroff and S. Belongie and P. Perona},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2010-001},
	Title = {{Caltech-UCSD Birds 200}},
	Year = {2010}
}

@INPROCEEDINGS{stripes,
  author={Z. {Fu} and T. A. {Xiang} and E. {Kodirov} and S. {Gong}},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Zero-shot object recognition by semantic manifold distance}, 
  year={2015},
  volume={},
  number={},
  pages={2635-2644},
  doi={10.1109/CVPR.2015.7298879}}
  
@article{fasttext,
  title={Enriching Word Vectors with Subword Information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1607.04606},
  year={2016}
}

@inproceedings{hnd,
  title={Hierarchical Novelty Detection for Visual Object Recognition},
  author={Lee, Kibok and Lee, Kimin and Min, Kyle and Zhang, Yuting and Shin, Jinwoo and Lee, Honglak},
  booktitle={CVPR},
  year={2018}
}

@article{wordnet, 
author = {Miller, George A.}, 
title = {WordNet: A Lexical Database for English},
year = {1995},
issue_date = {Nov. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {11}, issn = {0001-0782},
url = {https://doi.org/10.1145/219717.219748},
doi = {10.1145/219717.219748},
abstract = {Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].},
journal = {Commun. ACM},
month = nov,
pages = {39–41},
numpages = {3} }

@article{resnet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{imagenet,
  author={J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and  {Kai Li} and  {Li Fei-Fei}},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}

@INPROCEEDINGS{gmm,
  author={O. M. M. {Mohamed} and M. {Jaïdane-Saïdane}},
  booktitle={2009 17th European Signal Processing Conference}, 
  title={Generalized Gaussian mixture model}, 
  year={2009},
  volume={},
  number={},
  pages={2273-2277},
  doi={}}

@article {affinityprop,
	author = {Frey, Brendan J. and Dueck, Delbert},
	title = {Clustering by Passing Messages Between Data Points},
	volume = {315},
	number = {5814},
	pages = {972--976},
	year = {2007},
	doi = {10.1126/science.1136800},
	publisher = {American Association for the Advancement of Science},
	abstract = {Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such {\textquotedblleft}exemplars{\textquotedblright} can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called {\textquotedblleft}affinity propagation,{\textquotedblright} which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/315/5814/972},
	eprint = {https://science.sciencemag.org/content/315/5814/972.full.pdf},
	journal = {Science}
}

@ARTICLE{humanimageunderstanding,
    author = {Irving Biederman},
    title = {Recognition-by-components: A theory of human image understanding},
    journal = {Psychological Review},
    year = {1987},
    volume = {94},
    pages = {115--147}
}

@ARTICLE{gen-zsl,
  author={W. J. {Scheirer} and A. {de Rezende Rocha} and A. {Sapkota} and T. E. {Boult}},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Toward Open Set Recognition}, 
  year={2013},
  volume={35},
  number={7},
  pages={1757-1772},
  doi={10.1109/TPAMI.2012.256}}

@article{t-sne,
  author  = {Laurens van der Maaten and Geoffrey Hinton},
  title   = {Visualizing Data using t-SNE},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {86},
  pages   = {2579-2605},
  url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}

@article{resnet-101features,
author = {Jiang, Qingsheng and Tan, Dapeng and Li, Yanbiao and Ji, Shiming and Cai, Chaopeng and Zheng, Qiming},
year = {2019},
month = {12},
pages = {87},
title = {Object Detection and Classification of Metal Polishing Shaft Surface Defects Based on Convolutional Neural Network Deep Learning},
volume = {10},
journal = {Applied Sciences},
doi = {10.3390/app10010087}
}

@article{sil-score, author = {Rousseeuw, Peter}, title = {Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis}, year = {1987}, issue_date = {Nov. 1987}, publisher = {Elsevier Science Publishers B. V.}, address = {NLD}, volume = {20}, number = {1}, issn = {0377-0427}, url = {https://doi.org/10.1016/0377-0427(87)90125-7}, doi = {10.1016/0377-0427(87)90125-7}, journal = {J. Comput. Appl. Math.}, month = nov, pages = {53–65}, numpages = {13} }