\chapter{}{Literature Review}{Literature Review}

Zero-shot learning (ZSL) approaches can be broadly classified into two categories based on the unseen class information the model has during the training process. In the inductive ZSL framework, we have access to to labeled image data from the seen classes as well as auxiliary information (i.e., semantic attributes/descriptions) about both, seen and unseen classes during the training phase. In the transductive ZSL framework, we have access to auxiliary information (i.e., semantic attributes/descriptions) about both, seen and unseen classes during the training phase as in the case of the inductive ZSL framework. The major difference is that in the case of transductive ZSL, we have access to labeled image data from the seen classes \textit{and} unlabeled image data from the unseen classes during the training phase which is a departure from inductive ZSL. Within both frameworks, one can make an distinction based on the type of setting used to evaluate the model during testing. i.e. the conventional ZSL setting and generalized ZSL setting as described in Chapter 1. In this section we review work on both the inductive and transductive ZSL frameworks and place the proposed approach within the ZSL taxonomy.

\par
\medskip

Preliminary work in inductive ZSL uses a two-stage approach to infer unseen class labels. In the first stage, the attributes of an image are predicted. In the next stage, the class label is inferred by searching for the class label with the most similar set of attributes. Lampert et al~\cite{DAP} introduced the Directed Attribute Prediction (DAP) and Indirect Attribute Prediction (IAP) models  which use the aforementioned two-stage approach. In DAP~\cite{DAP}, a probabilistic attribute classifier is first learned. The class posteriors are then computed and class labels predicted via a maximum a posteriori (MAP) estimate. In IAP~\cite{DAP}, a multi-class classifier is first used to predict the class posterior. The probability of each class is then used to compute the attribute posteriors of an image. While the DAP and IAP frameworks have historically been some of the most widely cited ZSL methods in the literature, they suffer from the problem of domain shift~\cite{domainshift} where the intermediate functions learned from the auxiliary information without any adaptation to the target domain introduce an unknown bias.

\par
\medskip

Subsequent ZSL frameworks attempt to learn a compatibility function from image feature space to the semantic or auxiliary space. These frameworks can be further categorized based on the type of compatibility function that they learn. The first set of methods learn linear compatibility functions whereas the next set of methods learn non-linear compatibility functions.

\par
\medskip

\noindent
\textbf{Linear Compatibility.} Attribute Label Embedding (ALE)~\cite{ale} learns a bi-linear compatibility function between the image space and auxiliary space using a weighted approximate ranking objective. ALE improves upon DAP \cite{DAP} significantly since it can use multiple sources of auxiliary information such as word embeddings and class taxonomies. ALE also overcomes the drawbacks of the two-step process used in DAP by directly predicting the class label without the need for an intermediate step. The Deep Visual-Semantic Embedding (DEVISE) model~\cite{devise} also learns a linear mapping between the image space and semantic space and has been shown to perform well on the large-scale ImageNet data set. The Structured Joint Embedding (SJE) scheme~\cite{SJE} uses an unregularized structured SVM to learn the compatibility function coupled with the Stochastic Gradient Descent (SGD) algorithm for optimization. The Embarrassingly Simple Zero-Shot Learning (ESZSL) scheme~\cite{ESZSL} uses an additional regularization term to suppress noise in the auxiliary space. 

\par
\medskip

\noindent
\textbf{Non-Linear Compatibility.}  The Latent Embedding (LATEM) scheme~\cite{LATEM} extends linear compatibility approaches by learning multiple mappings thereby finding a piece-wise linear compatibility function using every image-class pair. LATEM shows improved accuracy over the state-of-art the linear compatibility-based SJE scheme~\cite{SJE}. The Cross-Modal Transfer (CMT) scheme~\cite{CMT} uses a neural network with two hidden layers to learn non-linear projections from image space to Word2Vec~\cite{w2v} space. CMT exploits only information from word embeddings and does not use other sources of auxiliary information such as class attributes used by other methods.
%%% SMB: INCLUDE THE FOLLOWING REFERENCE AND CITATION FOR CMT:
%%% R. Socher, M. Ganjoo, C.D. Manning and A.Y. Ng, Zero-Shot Learning Through Cross-Modal Transfer, Proc. NIPS 2013.  

\par
\medskip

Drawing from linear and non-linear compatibility approaches, hybrid models~\cite{gbu} learn a joint embedding of both the image and semantic features into a combined intermediate space. The Semantic Similarity Embedding (SSE) scheme~\cite{sse} uses a max-margin framework to jointly optimize domain data and semantic data. The Convex Combination of Semantic Embeddings (CONSE) scheme~\cite{conse} is inspired by DEVISE~\cite{devise} and maps images into the semantic embedding space via convex combination of the class label embedding vectors without the need for additional training. Synthesized Classifiers (SYNC) \cite{sync} introduces a set of “phantom” object classes whose coordinates exist in both the semantic space and the model space which are then optimized using labeled data such that the synthesized real object classifiers achieve optimal discriminating performance. Wang et al.~\cite{gcn} use a Graph Convolution Network (GCN) and the GLoVe text embedding model~\cite{glove} to generate a knowledge graph embedding. The knowledge graph embedding exploits both, semantic embeddings and domain relationships to predict the object classifiers. 
%%% SMB: INCLUDE THE FOLLOWING REFERENCE AND CITATION FOR CONSE:
%%% M. Norouzi, T. Mikolov, S. Bengio, Y. Singer, J. Shlens, A. Frome, G.S. Corrado, and J. Dean, Zero-Shot Learning by Convex Combination of Semantic Embeddings, Proc. ICLR, 2014. 

\par
\medskip

Recently, there has been a rise in the use of generative models for ZSL that represent each class as a probability distribution. Generative Framework for Zero-Shot Learning (GFZSL)~\cite{gfzsl} models the class-conditional distributions of seen as well as unseen classes using a multi-variate Gaussian distribution. Generative models such as GFZSL exhibit a significant performance boost in the transductive ZSL setting. The Feature Generating Network (FGN)~\cite{fgn} introduces a novel Generative Adversarial Network (GAN) that synthesizes Convolutional Neural Network (CNN) features conditioned on class-level semantic information, offering a direct shortcut  from a semantic descriptor of a class to a class-conditional feature distribution. The Leveraging the Invariant Side GAN (LisGAN) approach~\cite{LISGAN} generates unseen features from random noise functions which are conditioned by the semantic descriptions. They train a conditional Wasserstein GAN in which the generator synthesizes fake unseen features from noises and the discriminator distinguishes the fake from real via a minimax game. The recent approach based on leveraging the semantic relationships between the seen and unseen object categories termed as LsrGAN~\cite{lsrGAN} performs explicit knowledge transfer by incorporating a novel Semantic Regularized Loss (SR-Loss) function. A Tensorflow-based combination of a Variable Auto-Encoder (VAE) and GAN, termed as TF-vaegan~\cite{tf-vegan}, introduces a feedback loop from a semantic embedding decoder, that iteratively refines the generated features during both the training and feature synthesis stages. The synthesized features together with their corresponding latent embeddings from the decoder are then transformed into discriminative features and exploited during classification to reduce the ambiguities amongst the categories. The TF-vaegan framework~\cite{tf-vegan} is currently regarded as the benchmark in inductive and transductive ZSL settings on the AWA2~\cite{awa}, CUB~\cite{cub}, and SUN~\cite{sun} data sets on the zero-shot learning and generalized zero-shot learning settings. 

\par
\medskip

The proposed framework draws from the two-stage approach used by the DAP and IAP approaches~\cite{DAP} but the problem being addressed is substantially different from the standard ZSL problem that the aforementioned ZSL frameworks are designed for. Note that the proposed approach aims to predict a large number of unseen classes from few seen classes, and consequently, we have far less training data compared to the conventional ZSL settings. Hence, generative-adversarial-based and compatibility learning-based ZSL frameworks which require a lot of training data would be expected to perform poorly in this situation. The proposed ZSL framework represents a first step towards a novel ZSL problem formulation that strives to understand how classification accuracy measures change with change in number and type of seen classes. The proposed framework also allows for selection of an optimal number and type of seen classes based on an expected overall classification accuracy measure which aids in the training data collection process.

\newpage