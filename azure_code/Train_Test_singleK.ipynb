{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "import os \n",
    "import numpy as np \n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "img_width,img_height = 224, 224\n",
    "#nb_train_samples =400 \n",
    "#nb_validation_samples = 100\n",
    "epochs = 4\n",
    "batch_size = 16\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(),'BlobStorage')\n",
    "validation_data_dir = os.path.join(data_dir, 'validation_data')\n",
    "train_data_dir = os.path.join(data_dir, 'train_data')\n",
    "\n",
    "\n",
    "    \n",
    "train_datagen = ImageDataGenerator( \n",
    "    rescale=1. / 255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True) \n",
    "  \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "\n",
    "f = open(\"fasttext/clusterCenters.txt\",'r')\n",
    "\n",
    "lines = f.readlines()\n",
    "\n",
    "#print(lines)\n",
    "\n",
    "line = lines[0].split()\n",
    "print(line)\n",
    "modelName = line[0]\n",
    "classesNow = line[1:]\n",
    "print(modelName)\n",
    "print(classesNow)\n",
    "f.close()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "#classesNow = ['car','coffee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory( \n",
    "        train_data_dir, \n",
    "        classes = classesNow,\n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        class_mode='categorical') \n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( \n",
    "        validation_data_dir, \n",
    "        classes = classesNow,\n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        class_mode='categorical') \n",
    "\n",
    "n_classes = len(np.unique(train_generator.classes))\n",
    "channel = 3\n",
    "\n",
    "\n",
    "\n",
    "base_model=VGG19(weights='imagenet',include_top=False) \n",
    "#base_model=ResNet50(weights='imagenet',include_top=False) \n",
    "#base_model=InceptionResNetV2(weights='imagenet',include_top=False) \n",
    "print(type(base_model))\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(n_classes,activation='softmax')(x) #final layer with softmax activation with n_classes \n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional VGG19 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['categorical_accuracy','accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "model.fit_generator( \n",
    "        train_generator, \n",
    "        steps_per_epoch=train_generator.n // batch_size, \n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator, \n",
    "        validation_steps=validation_generator.n // batch_size)\n",
    "\n",
    "modelNameStr = \"trained_models/\"  + modelName +\".h5\"\n",
    "model.save(modelNameStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(),'BlobStorage')\n",
    "test_data_dir = os.path.join(data_dir, 'test_data_20') # the categories need to be in folders\n",
    "print(test_data_dir)\n",
    "\n",
    "img_width,img_height = 224, 224\n",
    "batch_size = 16\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory( \n",
    "        test_data_dir, \n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        #class_mode='categorical',\n",
    "        class_mode=None,\n",
    "        shuffle = False) \n",
    "\n",
    "test_generator.reset()\n",
    "\n",
    "#Getting list of stored models in trained_models folder\n",
    "#models_list = [l for l in os.listdir(\"trained_models\") if l.endswith('.h5')]\n",
    "#print(models_list)\n",
    "\n",
    "#model = load_model(\"model_contextobject_4classes.h5\")\n",
    "\n",
    "filenames =  test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "print('nb_samples '+str(nb_samples))\n",
    "print(filenames[1])\n",
    "#predictions = model.predict_generator(test_generator, steps=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "f = open(\"fasttext/clusterCenters.txt\",'r')\n",
    "\n",
    "lines = f.readlines()\n",
    "\n",
    "\n",
    "line = lines[0].split()\n",
    "print(line)\n",
    "modelName = line[0]\n",
    "classesNow = line[1:]\n",
    "f.close()\n",
    "\n",
    "#Keras sorts the list of classes used for training\n",
    "classesNow.sort()\n",
    "    \n",
    "model = load_model('trained_models/'+modelName+'.h5')\n",
    "predictions = model.predict_generator(test_generator, steps=nb_samples/batch_size, verbose = 1)\n",
    "pred_df = pd.DataFrame(data=predictions, index=filenames, columns=classesNow)\n",
    "#pred_df = pd.DataFrame(data=predictions, index=filenames, columns=['car','coffee'])\n",
    "print(pred_df.head())\n",
    "print(pred_df.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#Finding highest probability category\n",
    "pred_df['max_prob'] = pred_df.idxmax(axis=1)\n",
    "pred_df['max_prob'].to_csv('predictions/'+modelName+'.txt', header=True, index=True, sep=',',mode = 'w+')\n",
    "    #pred_df.to_pickle('predictions/'+modelName+'.pkl') \n",
    "print(pred_df.head())\n",
    "print(pred_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "pred_df = pd.read_csv('predictions/'+modelName+'.txt', header=0, sep=',')\n",
    "\n",
    "pred_df.columns = ['test_file','max_prob']\n",
    "pred_df['actual_label'] = pred_df.test_file.apply(lambda x: x.split('/')[0])\n",
    "\n",
    "results = confusion_matrix(pred_df['actual_label'], pred_df['max_prob']) \n",
    "print(results)\n",
    "\n",
    "print('Accuracy Score :',accuracy_score(pred_df['actual_label'], pred_df['max_prob']))\n",
    "\n",
    "print('Report : ')\n",
    "print(classification_report(pred_df['actual_label'], pred_df['max_prob']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
