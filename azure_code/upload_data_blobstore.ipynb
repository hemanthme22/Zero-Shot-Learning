{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Azure-Samples/storage-blobs-python-quickstart/blob/master/example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, uuid, sys\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "import time\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "train_file = 'noun-curatedTrain-df.csv'\n",
    "validation_file = 'noun-curatedValidation-df.csv'\n",
    "\n",
    "def download_data_vm():\n",
    "    ip_file = open(train_file, 'r+')\n",
    "    old_ctg = ''\n",
    "    \n",
    "    image_dict = {}\n",
    "    for l in ip_file.readlines()[1:]:\n",
    "        l_split = l.split('\\t')\n",
    "        ctg, img_link = l_split[1], l_split[2].rstrip()\n",
    "\n",
    "        \n",
    "        if ctg in image_dict:\n",
    "            if len(image_dict[ctg]) > 2000:\n",
    "                continue\n",
    "            image_dict[ctg].append(img_link)\n",
    "        else:\n",
    "            image_dict[ctg] = [img_link]\n",
    "            \n",
    "        \n",
    "        if len(image_dict) == 400: \n",
    "            break\n",
    "            \n",
    "    \n",
    "#     data_folder = os.path.join(os.getcwd(), 'validation_data')\n",
    "#     test_data_folder = os.path.join(os.getcwd(), 'test_data')\n",
    "    train_data_folder = os.path.join(os.getcwd(), 'train_data')\n",
    "    \n",
    "#     if os.path.exists(data_folder):\n",
    "#         shutil.rmtree(data_folder)\n",
    "    \n",
    "#     if os.path.exists(test_data_folder):\n",
    "#         shutil.rmtree(test_data_folder)\n",
    "        \n",
    "    if os.path.exists(train_data_folder):\n",
    "        shutil.rmtree(train_data_folder)\n",
    "        \n",
    "#     os.makedirs(data_folder, exist_ok=True)\n",
    "#     os.makedirs(test_data_folder, exist_ok=True)\n",
    "    os.makedirs(train_data_folder, exist_ok=True)\n",
    "        \n",
    "    for k, v in image_dict.items():\n",
    "#         val_cat_data_folder = os.path.join(data_folder, k)\n",
    "#         os.makedirs(val_cat_data_folder, exist_ok=True)\n",
    "        \n",
    "#         test_cat_data_folder = os.path.join(test_data_folder, k)\n",
    "#         os.makedirs(test_cat_data_folder, exist_ok=True)\n",
    "        \n",
    "        train_cat_data_folder = os.path.join(train_data_folder, k)\n",
    "        os.makedirs(train_cat_data_folder, exist_ok=True)\n",
    "        \n",
    "        for counter,url in enumerate(v):\n",
    "#             if counter < 499:\n",
    "#                 download_folder = val_cat_data_folder\n",
    "#             else:\n",
    "#                 download_folder = test_cat_data_folder\n",
    "            download_folder = train_cat_data_folder\n",
    "    \n",
    "            try:\n",
    "                #urllib.request.urlretrieve(url, filename=os.path.join(download_folder, url.rsplit('/', 1)[-1]))\n",
    "                open_save(url,os.path.join(download_folder, url.rsplit('/', 1)[-1]))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "def download_val_test_data_vm():\n",
    "    ip_file = open(validation_file, 'r+')\n",
    "    old_ctg = ''\n",
    "    \n",
    "    image_dict = {}\n",
    "    for l in ip_file.readlines()[1:]:\n",
    "        l_split = l.split('\\t')\n",
    "        ctg, img_link = l_split[1], l_split[2].rstrip()\n",
    "\n",
    "        \n",
    "        if ctg in image_dict:\n",
    "            if len(image_dict[ctg]) > 1000:\n",
    "                continue\n",
    "            image_dict[ctg].append(img_link)\n",
    "        else:\n",
    "            image_dict[ctg] = [img_link]\n",
    "            \n",
    "        \n",
    "        if len(image_dict) == 400: \n",
    "            break\n",
    "            \n",
    "    \n",
    "    data_folder = os.path.join(os.getcwd(), 'validation_data')\n",
    "    test_data_folder = os.path.join(os.getcwd(), 'test_data')\n",
    "\n",
    "    \n",
    "    if os.path.exists(data_folder):\n",
    "        shutil.rmtree(data_folder)\n",
    "    \n",
    "    if os.path.exists(test_data_folder):\n",
    "        shutil.rmtree(test_data_folder)\n",
    "        \n",
    "\n",
    "        \n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    os.makedirs(test_data_folder, exist_ok=True)\n",
    "\n",
    "        \n",
    "    for k, v in image_dict.items():\n",
    "        val_cat_data_folder = os.path.join(data_folder, k)\n",
    "        os.makedirs(val_cat_data_folder, exist_ok=True)\n",
    "        \n",
    "        test_cat_data_folder = os.path.join(test_data_folder, k)\n",
    "        os.makedirs(test_cat_data_folder, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        for counter,url in enumerate(v):\n",
    "            if counter < 499:\n",
    "                download_folder = val_cat_data_folder\n",
    "            else:\n",
    "                download_folder = test_cat_data_folder\n",
    "\n",
    "    \n",
    "            try:\n",
    "                open_save(url,os.path.join(download_folder, url.rsplit('/', 1)[-1]))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def open_save(url,path):\n",
    "    request_ = urllib.request.urlopen(url, timeout=10)\n",
    "    with open(path+'.jpg', 'wb') as f:\n",
    "        try:\n",
    "            f.write(request_.read())\n",
    "            f.flush()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "# Main method.\n",
    "if __name__ == '__main__':\n",
    "    download_data_vm()\n",
    "    download_val_test_data_vm()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from azureml.core import Workspace\n",
    "# load workspace configuration from the config.json file in the current folder.\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "\n",
    "train_data_folder = os.path.join(os.getcwd(), 'train_data')\n",
    "test_data_folder = os.path.join(os.getcwd(), 'test_data')\n",
    "validation_data_folder = os.path.join(os.getcwd(), 'validation_data')\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "ds.upload(src_dir=train_data_folder, target_path='guessingobject_context_train', overwrite=True, show_progress=False)\n",
    "ds.upload(src_dir=test_data_folder, target_path='guessingobject_context_test', overwrite=True, show_progress=False)\n",
    "ds.upload(src_dir=validation_data_folder, target_path='guessingobject_context_validation', overwrite=True, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
