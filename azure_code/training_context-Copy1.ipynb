{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/flyyufelix/cnn_finetune/blob/master/vgg19.py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def vgg19_model(img_rows, img_cols, channel=None, num_classes=None):\n",
    "    \"\"\"\n",
    "    VGG 19 Model for Keras\n",
    "    Model Schema is based on \n",
    "    https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d\n",
    "    ImageNet Pretrained Weights \n",
    "    https://drive.google.com/file/d/0Bz7KyqmuGsilZ2RVeVhKY0FyRmc/view?usp=sharing\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(img_rows, img_cols,channel)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Add Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    # Loads ImageNet pre-trained data\n",
    "    model.load_weights('vgg19_weights.h5')\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    model.layers.pop()\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Keras VGG19 for transfer learning\n",
    "import keras\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "base_model=VGG19(weights='imagenet',include_top=False) \n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(3,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model20\n",
      "['sunset', 'railway', 'river', 'shoulder', 'bike', 'painting', 'coin', 'coffee', 'championship', 'bag', 'football', 'photograph', 'scene', 'weather', 'shore', 'room', 'car', 'dress', 'roof', 'video']\n",
      "Found 29905 images belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0303 01:36:01.183158 140287431530240 deprecation_wrapper.py:119] From /anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7640 images belonging to 20 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0303 01:36:01.397815 140287431530240 deprecation_wrapper.py:119] From /anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0303 01:36:01.469018 140287431530240 deprecation_wrapper.py:119] From /anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0303 01:36:01.579469 140287431530240 deprecation_wrapper.py:119] From /anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0303 01:36:06.091310 140287431530240 deprecation_wrapper.py:119] From /anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0303 01:36:06.092213 140287431530240 deprecation_wrapper.py:119] From /anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0303 01:36:25.382397 140287431530240 deprecation_wrapper.py:119] From /anaconda/envs/py36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0303 01:36:25.558856 140287431530240 deprecation.py:323] From /anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " 352/1869 [====>.........................] - ETA: 22:28 - loss: 2.4923 - acc: 0.2413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1703936 bytes but only got 0. Skipping tag 42\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 256000 bytes but only got 0. Skipping tag 19200\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1285203968 bytes but only got 0. Skipping tag 59392\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/anaconda/envs/py36/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 9. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869/1869 [==============================] - 1862s 996ms/step - loss: 2.1760 - acc: 0.3348 - val_loss: 1.9276 - val_acc: 0.4125\n",
      "Epoch 2/4\n",
      "1869/1869 [==============================] - 664s 355ms/step - loss: 1.9776 - acc: 0.3959 - val_loss: 1.8282 - val_acc: 0.4332\n",
      "Epoch 3/4\n",
      "1869/1869 [==============================] - 663s 355ms/step - loss: 1.9154 - acc: 0.4099 - val_loss: 1.7952 - val_acc: 0.4466\n",
      "Epoch 4/4\n",
      "1868/1869 [============================>.] - ETA: 0s - loss: 1.8691 - acc: 0.4256"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "import os \n",
    "import numpy as np \n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "img_width,img_height = 224, 224\n",
    "#nb_train_samples =400 \n",
    "#nb_validation_samples = 100\n",
    "epochs = 4\n",
    "batch_size = 16\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(),'BlobStorage')\n",
    "validation_data_dir = os.path.join(data_dir, 'validation_data')\n",
    "train_data_dir = os.path.join(data_dir, 'train_data')\n",
    "\n",
    "\n",
    "    \n",
    "train_datagen = ImageDataGenerator( \n",
    "    rescale=1. / 255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True) \n",
    "  \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "\n",
    "f = open(\"fasttext/clusterCenters.txt\",'r')\n",
    "\n",
    "lines = f.readlines()\n",
    "\n",
    "#print(lines)\n",
    "\n",
    "for line in lines:\n",
    "  \n",
    "    line = line.split()\n",
    "   # print(line)\n",
    "    modelName = line[0]\n",
    "    classesNow = line[1:]\n",
    "    print(modelName)\n",
    "    print(classesNow)\n",
    "    train_generator = train_datagen.flow_from_directory( \n",
    "        train_data_dir, \n",
    "        classes = classesNow,\n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        class_mode='categorical') \n",
    "\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory( \n",
    "        validation_data_dir, \n",
    "        classes = classesNow,\n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        class_mode='categorical') \n",
    "    n_classes = len(np.unique(train_generator.classes))\n",
    "    channel = 3\n",
    "\n",
    "    #model = vgg19_model( img_width,img_height, channel=3, num_classes=n_classes)\n",
    "\n",
    "    base_model=VGG19(weights='imagenet',include_top=False) \n",
    "\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    #x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "    #x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "    preds=Dense(n_classes,activation='softmax')(x) #final layer with softmax activation with n_classes \n",
    "\n",
    "    model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional VGG19 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    model.fit_generator( \n",
    "        train_generator, \n",
    "        steps_per_epoch=train_generator.n // batch_size, \n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator, \n",
    "        validation_steps=validation_generator.n // batch_size)\n",
    "    modelNameStr = \"trained_models/\"  + modelName +\".h5\"\n",
    "    model.save(modelNameStr)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing code\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "import os \n",
    "import numpy as np \n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "img_width,img_height = 224, 224\n",
    "#nb_train_samples =400 \n",
    "#nb_validation_samples = 100\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(),'BlobStorage')\n",
    "validation_data_dir = os.path.join(data_dir, 'validation_data')\n",
    "train_data_dir = os.path.join(data_dir, 'train_data')\n",
    "\n",
    "train_datagen = ImageDataGenerator( \n",
    "    rescale=1. / 255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True) \n",
    "  \n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "\n",
    "f = open(\"fasttext/clusterCenters.txt\",'r')\n",
    "\n",
    "lines = f.readlines()\n",
    "\n",
    "#print(lines)\n",
    "\n",
    "#for line in lines:\n",
    "line = lines[0]  \n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = line.split()\n",
    "   # print(line)\n",
    "modelName = line[0]\n",
    "classesNow = line[1:]\n",
    "print(modelName)\n",
    "print(classesNow)\n",
    "train_generator = train_datagen.flow_from_directory( \n",
    "        train_data_dir, \n",
    "        classes = classesNow,\n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        class_mode='categorical') \n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( \n",
    "        validation_data_dir, \n",
    "        classes = classesNow,\n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        class_mode='categorical') \n",
    "n_classes = len(np.unique(train_generator.classes))\n",
    "channel = 3\n",
    "\n",
    "    #model = vgg19_model( img_width,img_height, channel=3, num_classes=n_classes)\n",
    "\n",
    "base_model=VGG19(weights='imagenet',include_top=False) \n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "#x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "#x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(n_classes,activation='softmax')(x) #final layer with softmax activation with n_classes \n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional VGG19 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "model.fit_generator( \n",
    "        train_generator, \n",
    "        steps_per_epoch=train_generator.n // batch_size, \n",
    "        epochs=epochs, \n",
    "        validation_data=validation_generator, \n",
    "        validation_steps=validation_generator.n // batch_size)\n",
    "#modelNameStr = \"trained_models/\"  + modelName +\".h5\"\n",
    "#model.save(modelNameStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget --no-check-certificate 'http://files.heuritech.com/weights/vgg19_weights.h5' -O vgg-16_weights.h5\n",
    "#!wget -O vgg19_weights.h5 https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "img_width,img_height = 224, 224\n",
    "batch_size = 16\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(),'BlobStorage')\n",
    "test_data_dir = os.path.join(data_dir, 'junk') # the categories need to be in folders\n",
    "print(test_data_dir)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory( \n",
    "        test_data_dir, \n",
    "        target_size=(img_width, img_height), \n",
    "        color_mode = 'rgb',\n",
    "        batch_size=batch_size, \n",
    "        #class_mode='categorical',\n",
    "        class_mode=None,\n",
    "        shuffle = False) \n",
    "\n",
    "test_generator.reset()\n",
    "\n",
    "#Getting list of stored models in trained_models folder\n",
    "models_list = [l for l in os.listdir(\"trained_models\") if l.endswith('.h5')]\n",
    "print(models_list)\n",
    "\n",
    "#model = load_model(\"model_contextobject_4classes.h5\")\n",
    "\n",
    "filenames =  test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "print('nb_samples '+str(nb_samples))\n",
    "print(filenames[1])\n",
    "#predictions = model.predict_generator(test_generator, steps=nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('trained_models/'+models_list[1])\n",
    "print(models_list[1])\n",
    "predictions = model.predict_generator(test_generator, steps=nb_samples/batch_size, verbose = 1)\n",
    "print(predictions)\n",
    "\n",
    "#predicted_class_indices=np.argmax(pred,axis=1)\n",
    "#labels = (validation_generator.class_indices)\n",
    "#labels2 = dict((v,k) for k,v in labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(predictions,axis=1)\n",
    "labels = (test_generator.class_indices)\n",
    "labels2 = dict((v,k) for k,v in labels.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
